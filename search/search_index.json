{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Machine Learning Interview Handbook","text":"Work in Progress <p>\ud83d\udea7  I am still working on this. Yet to do a lot of organization and add more relevant information. \ud83d\udea7</p> <p>About Me</p> <p>Hello there! \ud83d\udc4b</p> <p>I am a Computer Science Engineer with more than 8 years of working experience in the area of Deep Learning, Computer Vision. Over the years I have worked with some very well known institutions(IIT Kanpur, IIIT Delhi) and organizations(Mu Sigma Inc., Quantela Inc., Aditya Birla Group) researching, learning, and building Computer Vision applications.</p> <p>What is this?</p> <p>This handbook contains a collection of questions gathered from various sources, including:</p> <ol> <li>My Personal experience from both conducting and participating in interviews.</li> <li>Hands-on expertise in Deep Learning and Computer Vision.</li> <li>Research papers, online blogs, and articles I've read.</li> <li>Questions encountered during online courses.</li> </ol> <p>Liked my work? Do consider giving it a star on  GitHub</p>"},{"location":"activation-functions/","title":"Activation Functions","text":"What are activation functions? Why do we need non-linear activation functions in Neural Networks? <ul> <li>Activation functions are mathematical operations applied to the output of each neuron in a neural network. They introduce non-linearity into the output, allowing the network to learn complex relationships between inputs and outputs. Common activation functions include sigmoid, tanh, ReLU (rectified linear unit), and softmax.</li> </ul> What are some of the most commonly used activation functions? <ul> <li> <p>Read more:</p> <ul> <li> <p>https://www.v7labs.com/blog/neural-networks-activation-functions </p> </li> <li> <p>https://medium.com/analytics-vidhya/activation-functions-all-you-need-to-know-355a850d025e</p> </li> <li> <p>https://towardsdatascience.com/what-is-activation-function-1464a629cdca</p> </li> <li> <p>https://arxiv.org/pdf/2101.09957v1.pdf</p> </li> </ul> </li> </ul> Why should we avoid using Sigmoid activation in hidden layers? <ol> <li>It is a saturating function. It kills neurons with very large or very small input values.</li> <li>It\u2019s output is not zero-centered. Zero-centered data prevents zig zig updates to weights.</li> <li>Exponential functions are a bit expensive to compute hence it can slow down the network</li> </ol> Why does Tanh activation function works better than sigmoid for hidden units? <ul> <li>It usually works better than sigmoid activation function for hidden units because range of output lies between -1 to 1 therefore it solves the problem of zero-centering the data hence the mean of its output is closer to zero, and so it centers the data better for the next layer.</li> </ul> Can ReLUs be used for universal approximation? <ul> <li>Yes, ReLU (rectified linear unit) activation functions can be used for universal approximation. </li> <li> <p>Universal approximation refers to the property that a neural network with a single hidden layer containing a sufficient number of neurons can approximate any continuous function to any desired accuracy. This means that with enough neurons and appropriate training, a neural network with ReLU activation functions can model a wide range of complex, non-linear functions. However, in practice, it is typically necessary to use multiple hidden layers in order to achieve good performance on more difficult problems.</p> </li> <li> <p>Read more:</p> <ul> <li>If Rectified Linear Units Are Linear, How Do They Add Nonlinearity?</li> </ul> </li> </ul> Why or how is ReLU non-linear? <ul> <li> <p>The ReLU activation function is considered non-linear because it introduces non-linearity into the output of a neuron. The ReLU function takes the input value x and returns x if x is positive, and 0 if x is negative. This results in a step-like function, which is not a linear function, and is thus considered non-linear.</p> </li> <li> <p>Linear functions have the property that the output is proportional to the input, and the relationship between the input and output can be described by a single line. On the other hand, non-linear functions have more complex relationships between inputs and outputs, and cannot be described by a single line.</p> </li> <li> <p>By introducing non-linearity through the use of ReLU activation functions, neural networks are able to model more complex relationships between inputs and outputs, which is important for solving many real-world problems.</p> </li> </ul> Why do we use ReLUs when they are not differentiable? <ul> <li> <p>ReLU activation functions are not differentiable at x=0, but this is not a significant issue in practice because gradient-based optimization algorithms only need to be able to compute the gradient of the loss function with respect to the network parameters, not the activation function itself. The gradient of the ReLU function is simply 0 for x&lt;0, and 1 for x&gt;0, which can be easily calculated and used in optimization algorithms like stochastic gradient descent.</p> </li> <li> <p>ReLU activation functions have several advantages over other activation functions that make them popular for use in neural networks. They are computationally efficient, as they only require a simple comparison operation to calculate. They also introduce sparsity into the activations of the network, as many of the neurons will produce 0 output, making the network more interpretable and reducing the risk of overfitting. Additionally, they have been found to result in faster convergence and better performance on many problems compared to other activation functions.</p> </li> <li> <p>In conclusion, the lack of differentiability of ReLU at x=0 is not a significant issue in practice, and the benefits of using ReLU activation functions outweigh this limitation.</p> </li> </ul> What are some of the advantages and disadvantages of using ReLU? <p>Advantages:</p> <ol> <li> <p>Computationally Efficient: ReLU activation functions are simple and fast to compute, requiring only a simple comparison operation.</p> </li> <li> <p>Introduces Sparsity: ReLU activation functions introduce sparsity into the activations of the network, as many neurons will produce 0 output, making the network more interpretable and reducing the risk of overfitting.</p> </li> <li> <p>Improves Convergence: ReLU activation functions have been found to result in faster convergence and better performance on many problems compared to other activation functions.</p> </li> <li> <p>Non-saturating: ReLU activation functions do not saturate, meaning that they do not become asymptotic, which can improve the speed of convergence in some cases.</p> </li> <li> <p>Can be Used in Deep Networks: ReLU activation functions are often used in deep networks as they help to overcome the vanishing gradient problem, where the gradients become very small, making it difficult for the network to learn.</p> </li> </ol> <p>Disdvantages:</p> <ol> <li> <p>Dying ReLU Problem: ReLU activation functions can suffer from the \"dying ReLU\" problem, where a large number of neurons become inactive, producing 0 output, making it difficult for the network to learn.</p> </li> <li> <p>Sensitive to Noise: ReLU activation functions can be sensitive to noisy inputs, as a small change in the input can result in a large change in the output.</p> </li> <li> <p>Can cause Exploding Gradients: ReLU activation functions can sometimes cause exploding gradients, where the gradients become very large, making it difficult for the optimization algorithms to learn.</p> </li> <li> <p>May Require Careful Initialization: The weights of a network with ReLU activation functions may need to be initialized carefully in order to prevent the \"dying ReLU\" problem and to ensure that the network can learn effectively.</p> </li> </ol> <p>Read more:</p> <ul> <li> <p>https://iq.opengenus.org/relu-activation/</p> </li> <li> <p>https://www.kaggle.com/code/dansbecker/rectified-linear-units-relu-in-deep-learning/notebook</p> </li> </ul>"},{"location":"deep-learning-computer-vision/","title":"Deep Learning - Computer Vision","text":"Why do we use Convolutional Neural Networks(CNNs) for images/videos? What are the advantages of using CNNs over vanilla Neural Networks? <ol> <li> <p>Spatial arrangement: Information in an image makes more sense spatially. CNNs preserve spatial structure in images.</p> </li> <li> <p>Local Connectivity: CNNs take advantage of Local Spatial Coherence in the input. As opposed to vanilla Neural Networks where every neuron is connected to all neuron in the previous volume, in CNNs each neuron is connected to only a local region of the input volume. This local region exposed to a neuron in the input volume is called Local Receptive Field. Receptive field of a single unit within a layer is determined by the size of filter(width, height).</p> </li> <li> <p>Weight/Parameter Sharing: The weights of a kernel or filter used in a layer are learnable. This filter convolves with the input volume to produce an output feature map. The weights of a particular filter is shared across the input which produces this output. Due to this, a feature (say an edge, corner) learned at one spatial location doesn't need to be learned again if the same is found at another spatial location in the input.</p> </li> </ol> <p>Read more:</p> <ul> <li> <p>https://cs231n.github.io/convolutional-networks/</p> </li> <li> <p>https://towardsdatascience.com/understand-local-receptive-fields-in-convolutional-neural-networks-f26d700be16c</p> </li> <li> <p>https://towardsdatascience.com/understanding-parameter-sharing-or-weights-replication-within-convolutional-neural-networks-cc26db7b645a</p> </li> <li> <p>https://www.quora.com/What-are-the-advantages-of-a-convolutional-neural-network-CNN-compared-to-a-simple-neural-network-from-the-theoretical-and-practical-perspective</p> </li> <li> <p>https://msail.github.io/post/cnn_human_visual/</p> </li> </ul> What are Receptive Fields in CNNs? <p>https://distill.pub/2019/computing-receptive-fields/#overview</p> <p>https://blog.christianperone.com/2017/11/the-effective-receptive-field-on-cnns/</p> <p>https://theaisummer.com/receptive-field/</p>"},{"location":"feed-forward-nns/","title":"Feed Forward Neural Networks","text":"What are Feed Forward Neural Networks? <p>Feed Forward Neural Networks (FFNNs) are organized as a Directed Acyclic Graph (DAG) for computation. FFNNs have two passes: forward pass and backward pass.</p> <ul> <li> <p>The forward pass takes input data and passes it through a feature extractor, consisting of a linear transform and an activation function, to produce an output/prediction for either classification or regression. The loss is then calculated using a loss function.</p> </li> <li> <p>The backward pass uses the Backpropagation of error algorithm to calculate the gradients of the loss function with respect to the model parameters using the chain rule from the last layer to the first layer. Then, the Gradient Descent optimization algorithm updates the parameters to minimize the loss function.</p> </li> <li> <p>In summary, a FFNN is trained through the combination of Gradient Descent and Backpropagation.</p> </li> </ul> What is Gradient Descent? <ul> <li>Gradient Descent updates the parameters of the model to minimize the loss function by using the gradients of the loss function with respect to the parameters, which can be calculated through Backpropagation.</li> </ul> What is the use of Bias term? <ul> <li> <p>The bias term in a neural network is used to shift the activation function to the left or right, allowing the model to fit a more complex decision boundary and improve its accuracy.</p> </li> <li> <p>In other words, it acts as an additional model parameter and allows the model to account for different intercepts or offsets in the input-output mapping.</p> </li> </ul> Are neural networks convex? <ul> <li>No, in general, neural networks are not convex. </li> <li> <p>A convex optimization problem has a global minimum that can be found efficiently. However, neural networks can have multiple local minima and it can be challenging to find the global minimum. This is why training neural networks is often treated as a non-convex optimization problem and the use of optimization algorithms such as stochastic gradient descent and its variants are used to find good solutions.</p> </li> <li> <p>Neural networks are not essentially convex, since they are differentiable, they can be decomposed into a number of convex problems</p> </li> </ul> What are logits? <ul> <li>In machine learning, logits refer to the raw, unscaled prediction values that a neural network generates before the activation function is applied. </li> <li>The logits are typically transformed by an activation function, such as a sigmoid or softmax, to produce a probability distribution over output classes.</li> <li>The logits can be seen as the learned representation of input features by the network and are often used to calculate loss functions during training.</li> </ul>"},{"location":"loss-functions/","title":"Loss Functions","text":"What is a cost function? <ul> <li> <p>In deep learning, a cost function, also known as a loss function, is a mathematical function that measures the difference between the predicted output of a model and the actual target output. The goal of training a deep learning model is to minimize the value of the cost function, so that the model's predictions are as close as possible to the target outputs.</p> </li> <li> <p>The cost function is used to guide the optimization process during training by providing a measure of the error in the model's predictions. The optimization algorithm, such as stochastic gradient descent (SGD), updates the model's weights and biases in the direction that reduces the value of the cost function.</p> </li> <li> <p>There are many different cost functions that can be used in deep learning, depending on the type of problem being solved and the type of model being used. Common examples include mean squared error for regression problems, cross-entropy for binary classification problems, and categorical cross-entropy for multi-class classification problems.</p> </li> </ul> Cost vs Loss function? <ul> <li>Loss function is defined on a single training example.</li> <li>Cost function is defined on the entire training set.</li> </ul> What are some Regression Loss Functions? <ol> <li>Mean Absolute Error/L1</li> <li>Mean Squared Error/L2 </li> <li>Root Mean Squared Error</li> <li>Mean Bias Error</li> <li>Huber Loss</li> <li>Mean Squared Logarithmic Error Loss</li> <li>Mean Absolute Error Loss</li> </ol> <p>Choosing the right loss function for a regression problem depends on the specific requirements of the problem and the type of data being used. In general, MSE and MAE are a good starting point for most regression problems.</p> <p>Read more:</p> <ul> <li>Huber Loss: https://github.com/christianversloot/machine-learning-articles/blob/main/using-huber-loss-in-keras.md</li> </ul> What are some Classification Loss Functions? <ol> <li>Cross-Entropy Loss (Binary/Categorical)</li> <li>Hinge Loss</li> <li>Squared Hinge Loss</li> </ol> <p>Read more:</p> <ul> <li> <p>Cross Entropy Loss: https://gombru.github.io/2018/05/23/cross_entropy_loss/</p> </li> <li> <p>https://medium.com/analytics-vidhya/common-loss-functions-in-machine-learning-for-classification-model-931cbf564d42</p> </li> <li> <p>https://towardsdatascience.com/understanding-loss-functions-the-smart-way-904266e9393</p> </li> </ul> What are different types of Multi-Class Classification Loss Functions? <ol> <li>Binary Cross-Entropy (BCE) </li> <li>Categorical Cross-Entropy (CCE):</li> <li>Hinge Loss</li> <li>Kullback Leibler Divergence Loss</li> <li>Focal Loss</li> </ol> Probability vs likelyhood <p>Maximum likelihood seeks to find the optimum values for the parameters by maximizing a likelihood function derived from the training data.</p> <p>https://www.youtube.com/watch?v=pYxNSUDSFH4&amp;ab_channel=StatQuestwithJoshStarmer</p> Why do we use log? <p>What is logarithm? | Math, Statistics for data science, machine learning</p> What is information theory, entropy, cross-entropy, KL Divergence? <p>Information Theory:</p> <p>Very well explained in the beginning of this video</p> <p>Entropy:</p> <p>It is a measure of how uncertain the events are. It tells you how unpredictable that probability distribution is. The formula for entropy is:</p> <p>\\(Entropy = H(p) = -\\sum_ip_ilog_2(p_i)\\)</p> <p>It gives us the average amount of information that you get from one sample drawn from a given probability distribution \\(p\\)</p> <p>https://www.youtube.com/watch?v=YtebGVx-Fxw&amp;ab_channel=StatQuestwithJoshStarmer</p> <p>https://www.youtube.com/watch?v=IPkRVpXtbdY&amp;ab_channel=mfschulte222</p> <p>Cross Entropy</p> <p>https://www.youtube.com/watch?v=tRsSi_sqXjI&amp;ab_channel=Udacity</p> <p>https://www.youtube.com/watch?v=bLb_Kp5Q9cw&amp;ab_channel=MattYedlin</p> <p>https://www.youtube.com/watch?v=TIL0BU6917o&amp;ab_channel=DrJuanKlopper</p> <p>KL Divergence</p> <ul> <li> <p>The amount by which the cross entropy exceeds the entropy is called the relative entropy or commonly KL Divergence</p> </li> <li> <p>Cross Entropy = Entropy + KL Divergence</p> <p>\\(D_{KL}(p||q) = H(p, q) - H(p)\\)</p> </li> <li> <p>It is a measure of the information lost when Q is used to approximate P</p> <p>https://stats.stackexchange.com/questions/154879/a-list-of-cost-functions-used-in-neural-networks-alongside-applications</p> </li> </ul> How are entropy and probability related? <p>https://www.analyticsvidhya.com/blog/2020/11/entropy-a-key-concept-for-all-data-science-beginners/</p> Categorical Cross Entropy Loss vs Sparse Categorical Cross Entropy Loss <p>The main difference is the former one has the output in the form of one-hot encoded vectors whereas the latter has it in integers. </p> <p>The sparse version can also help you when you encounter memory constraint issues are used in multi-class classification. </p> <p>Sparse cross-entropy addresses this by performing the same cross-entropy calculation of error, without requiring that the target variable be one-hot encoded before training.</p>"},{"location":"machine-learning/","title":"Machine Learning","text":"What is the difference between Multinomial Logistic Regression and Softmax Regression? <p>Multinomial logistic regression and softmax regression (also known as maximum entropy classifier) are both machine learning algorithms used for multiclass classification problems, where the goal is to predict a categorical dependent variable with more than two categories. However, there are some differences between the two:</p> <ul> <li> <p>Formulation: Multinomial logistic regression models the relationship between the dependent variable and independent variables through multiple binary logistic regression models, one for each class. Softmax regression models the relationship through a single multiclass logistic regression model that calculates the probablities for all classes.</p> </li> <li> <p>Output: The output of multinomial logistic regression is a set of probabilities for each class, whereas the output of softmax regression is a set of scores that can be transformed into probabilities.</p> </li> <li> <p>Optimization: The optimization problem solved in multinomial logistic regression is a maximum likelihood estimation, while the optimization problem solved in softmax regression is a maximum entropy optimization.</p> </li> </ul> <p>In summary, both algorithms can be used for the same problem, but they differ in the way they model the relationship between the dependent variable and independent variables, the form of their output, and the optimization problem they solve.</p> <ul> <li>References:<ul> <li>https://www.kdnuggets.com/2016/07/softmax-regression-related-logistic-regression.html</li> </ul> </li> </ul>"},{"location":"model-evaluation/","title":"Model Evaluation","text":"Confusion Matrix Question <ul> <li>Proportion of correct predictions(TP, TN) made by model out of a total number of cases (correct: TP, TN+in correct: FP, FN)?</li> <li>Formula: (TP+TN)/(TP+TN+FP+FN)</li> <li>Usage: Used in cases where classes are well balanced.</li> <li>When not to use?: If the target variable is sparse</li> </ul> Precision <ul> <li>Proportion of model's correct Positive predictions(TP) out of total Positive predictions (TP+FP)</li> <li>In my words: the model made positive predictions(TP, FP); I want to know what proportion of them were actually positive(TP)</li> <li>Formula: TP/(TP+FP)</li> <li>Usage:  Use when you want to be very sure of your prediction. In case of stock investments, say we develop a model that determines if a stock will be a good investment or not. If we were to pour our entire net worth into this one stock, we would better hope that our model is right. Precision would be the best metric to use here because it determines the correctness of our model. We can afford to miss a few profitable stock investments here and there (so recall score is not as important), as long as our money is going to an appreciating stock correctly predicted by our model.</li> </ul> Recall <ul> <li>Proportion of actual positives(TP, FN) correctly classified as positives(TP) </li> </ul> Average Precision <p>Average Precision (AP) is defined as an area under the precision/recall curve.</p> <p>The 5 Classification Evaluation metrics every Data Scientist must know</p> <p>Multi-Class Metrics Made Simple, Part II: the F1-score</p> <p>Confusion Matrix</p> <p>Machine Learning Basics: Confusion Matrix &amp; Precision/Recall Simplified | By Dr. Ry @Stemplicity</p> <p>Based on Confusion Matrix</p> <pre><code>1. Acurracy\n\n    $(TP+TN)/(TP+TN+FP+FN)$\n\n2. Error rate\n3. precision\n4. Sensitivty = TPR(True Positive Rate)= Recall = TP/(TP+FN)\n    - True positive rate or TPR is just the proportion of trues we are capturing using our algorithm.\n    - TPR = TP/ALL POSITIVES\n5. Specificity\n6. 1- Specificity = FPR(False Positive Rate)= FP/(TN+FP)\n    - False positive rate or FPR is just the proportion of false we are capturing using our algorithm.\n    - FPR = FP/ALL NEGATIVES\n7. F1 Score = 1/2(1/P + 1/R) = 2*(P*R)/(P+R)\n    - It is the harmonic mean of Precision and Recall\n\n[https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/](https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/)\n\n[Machine Learning Basics: Confusion Matrix &amp; Precision/Recall Simplified | By Dr. Ry @Stemplicity](https://www.youtube.com/watch?v=CYy0TZ6OIDw&amp;ab_channel=Stemplicity)\n</code></pre> <ul> <li> <p>Sensitivity and Specificity</p> <p>Machine Learning Fundamentals: Sensitivity and Specificity</p> </li> <li> <p>ROC, AUC</p> <p>ROC and AUC, Clearly Explained!</p> </li> <li> <p>Top-1 and Top-5 accuracy</p> <p>Check alexnet paper</p> </li> </ul> <p>https://www.dlology.com/blog/simple-guide-on-how-to-generate-roc-plot-for-keras-classifier/</p> <ul> <li> <p>Metrics</p> <pre><code>accuracy is not to be used\nim balanced class\nprevelance - how much of positive vlaues in data\npositive predictive power\nnpv\nxg boost - parameters\n</code></pre> </li> </ul>"},{"location":"model-training/","title":"Model Training","text":"What is iteration, epoch, batch size, step size? <ul> <li> <p>A Forward Backward and forward pass makes together one\u00a0iteration.</p> </li> <li> <p>During one iteration we can either pass a subset of dataset or \u201cmini-batch\u201dor the entire dataset \u201cbatch\u201d.</p> </li> <li> <p>One full pass through the entire dataset(full batch or in mini-batches) is known as an epoch. One epoch contains (number_of_items / batch_size) iterations.</p> </li> <li> <p>Step size</p> </li> </ul> <p>https://stackoverflow.com/questions/36740533/what-are-forward-and-backward-passes-in-neural-networks</p> <p>https://spell.ml/blog/lr-schedulers-and-adaptive-optimizers-YHmwMhAAACYADm6F</p> What is the effect of varying batch size on asymptotic test accuracy? Why using mini-batch gradient descent is a good choice? What does a large gap between training and validation graph signifies? <p>If there\u2019s a big gap between the training and the validation curves, clearly the model strongly overfits. </p> Reasons we get NaN in loss values when training a neural network How do you decide the learning rate for training a model? How to speed up your learning?  <p>(From Coursera Deep Learning Sp)</p> <p>Use Learning rate decay!</p> <p>The idea is as you move towards convergence, using a fixed learning rate, you might wander around the optima but may not reach it so reducing the LR can help converge.</p> <p>During the initial phase, when LR is large, you can still have relatively fast learning, meaning that during initial steps of learning you can afford to take larger steps but as and when you approach convergence, then having a lower learning rate can allow you to take smaller steps</p> <p>Decay Rate is a HYPERPARAMETER that one needs to choose just like the learning rate.</p> Vanishing or Exploding Gradients <ul> <li>can be improved by careful weight initialization - partial solution</li> </ul>"},{"location":"optimizers/","title":"Optimizers","text":"Explain Gradient Descent Algorithm <p>Check Feed Forward Neural Networks section for explanation</p> Do we need to use a learning rate scheduler for adaptive optimizers like Adam, AdaGrad? <p>We use use Learning Rate Scheduler with SGD but the same may not be required for Adaptive optimizers like Adam.</p> <p>Adam manages learning rates internally, it's incompatible with most learning rate schedulers.</p> <p>Adaptive optimizers eschew the use of a separate learning rate scheduler, choosing instead to embed learning rate optimization directly into the optimizer itself.</p> <p>It was discovered relatively early on that choosing a large initial learning rate then shrinking it over time leads to better converged, more performant models. This is known as annealing or decay.</p> <p>SGD + LR Scheduler works better than SGD + Fixed LR</p> <p>Some common LR Schedulers:</p> <ul> <li>ReduceLROnPlateau \u2192 SGD+ReduceLROnPlateau+EarlyStopping</li> <li>Cosine annealed warm restart</li> <li>One-cycle learning rate schedulers - superconvergence</li> </ul> <p>Found an answer on Stackexchange which warrants a discussion:</p> <p>https://stats.stackexchange.com/questions/286723/is-manually-tuning-learning-rate-during-training-redundant-with-optimization-met</p> <p>https://spell.ml/blog/lr-schedulers-and-adaptive-optimizers-YHmwMhAAACYADm6F</p> Difference between backprop and gradient descent? <p>Backpropagation is a process of calulating derivatives (using the chain rule in a feed forward neural network, the gradient calulcation flows from the last layer to the first layer)</p> <p>Gradient descent is an optimizer which is used to adjust the values of parameters</p> Is gradient descent first order or second order optimizer? <p>It is the first order optimizer</p> What are some second-order methods? Are they used in optimization? <p>We will not discuss algorithms that are infeasible to compute in practice for high-dimensional data sets, e.g. second-order methods such as Newton's method.</p> Explain Adam optimizer <ul> <li> <p>Adaptive Moment Estimation (Adam) is another method that computes adaptive learning rates for each parameter.</p> </li> <li> <p>In addition to storing an exponentially decaying average of past squared gradients\u00a0vt like Adadelta and RMSprop, Adam also keeps an exponentially decaying average of past gradients\u00a0mt similar to momentum.</p> </li> <li> <p>Adam is almost parameter-free. Adam does have a learning rate hyperparameter, but the adaptive nature of the algorithm makes it quite robust\u2014unless the default learning rate is off by an order of magnitude, changing it doesn't affect performance much.</p> </li> </ul> What is Synchronous SGD?"},{"location":"regularization-techniques/","title":"Regularization Techniques","text":"What is Regularization? <p>In the context of deep learning, regularization can be understood as the process of adding information / changing the objective function to prevent overfitting.</p> <p>It is intended to Lowering the generalization error of a model not the training error.</p> <p>Wikipedia</p> <p>https://medium.com/techspace-usict/normalization-techniques-in-deep-neural-networks-9121bf100d8</p> <p>Explicit techniques</p> <ul> <li> <p>L2 Norm/ L1 Norm - adding panelty to large wt in the cost function -  helps network to have smaller weights and also helps in making the network less sensitive to certain inputs so that makes network predictions less noisy - reduce variance</p> </li> <li> <p>Dropout - dropping rand units in the network - introduces noise to network</p> </li> </ul> <p>Implicit techniques</p> <ul> <li> <p>SGD</p> </li> <li> <p>Early Stopping - looking at validation set performance</p> </li> <li> <p>Getting more data</p> </li> <li> <p>Data Augmentation</p> </li> <li> <p>Reducing network capacity - Making network more robust</p> </li> <li> <p>Gradient Clipping - Helps in exploding gradient problem</p> </li> <li> <p>Normalization - more of setting up optimization problem for speeding up training</p> </li> </ul> Difference between L1 vs L2 Regularization? <ul> <li> <p>If you use L1 then the weight matrix w will end up being sparse, w will have a lot of zeros in it and some people say that it can help in compressing the model as some parameters will be zero then you need less memory to store the model</p> </li> <li> <p>In practice, L2 is used more in case of NNs</p> </li> <li> <p>For NNs, L2 norm is called Frobenius norm of a matrix</p> </li> <li> <p>L2 is also sometimes called weight decay</p> </li> </ul> What is Dropout?"},{"location":"resources/","title":"Resources","text":""},{"location":"resources/#deep-learning","title":"Deep Learning","text":"Full Courses from Top Universities  Top YouTubers  People Stanford University CS231n, Spring 2017 <ol> <li>Course Website</li> <li>YouTube Lectures Playlist</li> </ol> CS230: Deep Learning <ol> <li>Course Website</li> <li>Lecture Notes</li> <li>YouTube Lectures Playlist</li> </ol> Applied Deep Learning - UC Boulder by Prof. Maziar Raissi <ol> <li>Course GitHub</li> <li>YouTube Lectures Playlist</li> </ol> Deep Learning UC Berkeley STAT-157 2019 <ol> <li>Course GitHub</li> <li>YouTube Lectures Playlist</li> </ol> EECS 498-007 / 598-005 Deep Learning for Computer Vision <ol> <li>Course Website</li> <li>YouTube Lectures Playlist</li> </ol> MIT Introduction to Deep Learning | 6.S191 <ol> <li>Course GitHub</li> <li>YouTube Lectures Playlist</li> </ol> Cogneethi - Computer Vision <ol> <li>Course GitHub</li> <li>YouTube Lectures Playlist</li> </ol> Aleksa Gordi\u0107 - The AI Epiphany <ol> <li>YouTube Channel</li> </ol> Full Stack Deep Learning <ol> <li>New Website</li> <li>Old Website</li> <li>YouTube Channel</li> </ol> Aladdin Persson <ol> <li>YouTube Channel</li> </ol> Chip Huyen <ul> <li>Website</li> </ul> Jeremy Jordan <ul> <li>Website</li> </ul> Erika Lu <ul> <li>Website</li> </ul> Justin Johnson <ul> <li>Website</li> </ul> Jason Yosinski <ul> <li>Website</li> </ul> Chenxi Liu <ul> <li>Website</li> </ul> Louis Tiao <ul> <li>Website</li> </ul>"},{"location":"setting-up/","title":"Setting up Neural Networks","text":"Why is it important to have a zero-centered data? <ul> <li> <p>It is important to have zero-centered data for input to Neural Networks because it helps to ensure that the input features are on a similar scale, which can improve the performance of the network. When the features of the input data are on different scales, some features may dominate others, making it difficult for the network to learn meaningful representations of the data. By zero-centering the data, the mean of the input features is subtracted from each feature, so that the mean of the input data is 0.  </p> </li> <li> <p>Additionally, zero-centering the data can help to speed up convergence of the optimization algorithm, as it helps to ensure that the optimization problem is well-conditioned.</p> </li> </ul> What is feature scaling? <ul> <li> <p>Feature scaling is a pre-processing step in deep learning where the values of the input features are normalized to a common range. </p> </li> <li> <p>The goal of feature scaling is to avoid having input features with large magnitude dominate the learning process of the model. </p> </li> <li> <p>Common scaling techniques include standardization, where features are transformed to have zero mean and unit variance, and normalization, where features are rescaled to a specific range such as [0, 1].</p> </li> </ul> What is the difference between Standardization and Normalization? <ul> <li> <p>Standardization and normalization are two techniques used to preprocess input data in deep learning.</p> </li> <li> <p>Standardization involves transforming the data so that it has a mean of 0 and a standard deviation of 1. This means that the data is centered around the origin and scaled so that it has similar magnitudes. This is often used when the features in the input data have different scales and units, as it allows the model to treat all features equally.</p> </li> <li> <p>Normalization, on the other hand, involves transforming the data so that it has a minimum of 0 and a maximum of 1. This is often used when the input data is sparse and has a wide range of values. Normalization ensures that the scale of the data does not have an impact on the performance of the model.</p> </li> <li> <p>In summary, standardization is used to center and scale the data, while normalization is used to rescale the data so that it has a minimum and maximum value.</p> </li> </ul>"}]}